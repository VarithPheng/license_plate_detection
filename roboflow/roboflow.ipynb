{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Initialize Roboflow\n",
    "rf = Roboflow(api_key=\"zFMAHTN2KKDonwd6JydE\")\n",
    "project = rf.workspace().project(\"carplate-xuk6s\")\n",
    "model = project.version(1).model\n",
    "\n",
    "# Path to the directory containing images\n",
    "image_folder = \"../images\"\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Iterate over each image file\n",
    "for image_file in image_files:\n",
    "    # Construct the full path to the image\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Perform detection\n",
    "    result = model.predict(image_path, confidence=40, overlap=30).json()\n",
    "    labels = [item[\"class\"] for item in result[\"predictions\"]]\n",
    "    \n",
    "    # Convert predictions to the required format\n",
    "    xyxy = np.array([\n",
    "        (\n",
    "            item[\"x\"] - item[\"width\"] / 2,\n",
    "            item[\"y\"] - item[\"height\"] / 2,\n",
    "            item[\"x\"] + item[\"width\"] / 2,\n",
    "            item[\"y\"] + item[\"height\"] / 2\n",
    "        )\n",
    "        for item in result[\"predictions\"]\n",
    "    ])\n",
    "    \n",
    "    detections = sv.Detections(\n",
    "        xyxy=xyxy,\n",
    "        confidence=np.array([item[\"confidence\"] for item in result[\"predictions\"]]),\n",
    "        class_id=np.array([item[\"class_id\"] for item in result[\"predictions\"]])\n",
    "    )\n",
    "    \n",
    "    # Initialize annotators\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "    bounding_box_annotator = sv.BoxAnnotator()\n",
    "    \n",
    "    # Annotate the image\n",
    "    annotated_image = bounding_box_annotator.annotate(scene=image, detections=detections)\n",
    "    annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)\n",
    "    \n",
    "    # Display the annotated image\n",
    "    sv.plot_image(image=annotated_image, size=(16, 16))\n",
    "    # Optionally save the annotated image\n",
    "    # cv2.imwrite(f\"annotated_{image_file}\", annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Define the folder containing the images\n",
    "folder_path = \"plates\"\n",
    "\n",
    "# Tesseract configuration for optimal performance\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    "\n",
    "# Define a function to clean up common OCR errors\n",
    "def clean_text(text):\n",
    "    # Remove trailing or isolated characters (like \"ន\" at the end)\n",
    "    cleaned = re.sub(r'\\s+[ន]*$', '', text.strip())\n",
    "    return cleaned\n",
    "\n",
    "# Iterate through all images in the \"plates\" folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg')):  # Process only image files\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Resize the image for better recognition\n",
    "        image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "        # Convert to grayscale and apply adaptive thresholding\n",
    "        gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.adaptiveThreshold(\n",
    "            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "        )\n",
    "\n",
    "        # Perform OCR on the preprocessed image\n",
    "        raw_text = pytesseract.image_to_string(thresh, config=custom_config, lang='khm+eng')\n",
    "\n",
    "        # Apply the clean_text function to each line of the OCR result\n",
    "        lines = raw_text.strip().split('\\n')\n",
    "        cleaned_lines = [clean_text(line) for line in lines]\n",
    "\n",
    "        # Display the cleaned OCR result\n",
    "        print(f\"\\n[Cleaned Text from {filename}]:\")\n",
    "        for line in cleaned_lines:\n",
    "            print(line)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
